# PetGuardian IoT - README

## Overview
PetGuardian is a modular IoT system simulating a smart collar for outdoor pet safety.  
It uses active and passive sensors to detect environmental risks and control devices like LEDs and cameras.  
Both real hardware and virtual simulation are supported.

> **Note**:  
> Update your `.env` file to configure sensor modes (`True` or `False`).


## Quick Start
**Start Live Collar Mode:**
python main.py

**Start Guardian AI Mode**
python guardian.py

> `main.py` = Full system, automatic sensor startup.  
> `guardian.py` = Listen-only mode, manual triggers via running sesnor files or MQTT.

**Start Dashboard**
python dashboard/dashboard.py


## Sensor Scripts - Interactive Mode

Each sensor (`gps_sensor.py`, `camera_sensor.py`, etc.) can run alone for testing.

How it works:
- Run the script directly → interactive test mode.
- Hardware missing? → simulation options are provided.

Example commands:
python sensors/gps_sensor.py
python sensors/camera_sensor.py

Example prompts:

[INTERACTIVE] Type 'G' to simulate GPS event, or 'X' to exit.
[INTERACTIVE] Select test image: 1-Dog  2-Bike  3-Human


Outputs:
- Console
- Local Logs (`/data/logs/`)
- Azure IoT Hub + Cosmos DB


## MQTT Test Triggers

When running `guardian.py`, send MQTT messages to simulate events:

| Action | Topic | Payload |
|:---|:---|:---|
| Trigger GPS | `petguardian/trigger/gps` | `{ "command": "get_gps" }` |
| Trigger Camera | `petguardian/trigger/camera` | `{ "command": "get_camera" }` |
| Control Bulb | `petguardian/trigger/bulb` | `{ "command": "turn_on" }` or `{ "command": "turn_off" }` |

Use HiveMQ, MQTT Explorer, or Python script to publish these.

## Folder Structure

PetGuardian-IoT/
├── ai/                # AI controllers (guardian.py, threats_ai.py)
├── dashboard/         # Dashboard UI and tools
├── sensors/           # Sensor modules (gps, camera, etc.)
│   └── utils/         # Shared utilities (SensorUtils.py)
├── data/
│   ├── logs/          # Sensor logs and event data
│   └── images/        # Camera image captures
├── tests/             # Test scripts and test images
└── main.py            # Start system in live collar mode


## Notes
- All scripts support both **Real** and **Virtual** sensor modes via `.env`.
- Threads are used to prevent blocking during sensor listening.
- Full Azure integration: IoT Hub + Cosmos DB storage.

